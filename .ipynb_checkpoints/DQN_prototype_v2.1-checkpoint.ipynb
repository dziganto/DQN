{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import deque\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(rgb_tensor):\n",
    "    '''\n",
    "    Transforms 3D RGB numpy tensor: crop, convert to 2D grayscale, downsample, and convert to PyTorch tensor.\n",
    "    '''\n",
    "    crop = rgb_tensor[30:194,:,:]\n",
    "    grayscale = np.dot(crop[...,:3], [0.2989, 0.5870, 0.1140])  ## using Matlab's formula\n",
    "    downsample = skimage.measure.block_reduce(grayscale, (2,2), np.max)\n",
    "    return downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Select Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action:\n",
    "    '''Returns an action value which is an int in range [0,3]'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.time_ = 0\n",
    "        \n",
    "    def update_time(self):\n",
    "        self.time_ += 1\n",
    "        \n",
    "    def action(self):\n",
    "        if self.time_ == 0:\n",
    "            self.action_ = 1  ## start game by firing ball\n",
    "        else:\n",
    "            # take agent-based action every 4 time steps; else push action forward w/out agent computing\n",
    "            if self.time_%4 == 0:\n",
    "                if np.random.binomial(n=1, p=eg.epsilon_, size=1):\n",
    "                    self.action_ = env.action_space.sample()  ## take random action\n",
    "                else:\n",
    "                    self.action_ = cnn(Variable(torch.Tensor(initial_seq).unsqueeze(0).unsqueeze(0))).data.max(1)[1][0]  ## take optimal action according to NN\n",
    "        return self.action_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExperienceReplay:\n",
    "    \n",
    "    dq_ = deque(maxlen=500)\n",
    "\n",
    "    def __init__(self, C):\n",
    "        self.capacity_ = C\n",
    "        \n",
    "    def add_experience(self, experience_tuple):\n",
    "        '''add new experience to experience replay'''\n",
    "        self.dq_.append(experience_tuple)\n",
    "        \n",
    "    def sample(self, capacity=32):\n",
    "        '''sample from experience replay'''\n",
    "        nb_items = len(self.dq_)\n",
    "        if nb_items > capacity:\n",
    "            idx = np.random.choice( nb_items, size=capacity, replace=False)\n",
    "        else:\n",
    "            idx = np.random.choice( nb_items, size=nb_items, replace=False)\n",
    "        return [self.dq_[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EpsilonGenerator():\n",
    "    \n",
    "    def __init__(self, start, stop, steps):\n",
    "        self.epsilon_ = start\n",
    "        self.stop_ = stop\n",
    "        self.steps_ = steps\n",
    "        self.step_size_ = (self.epsilon_ - stop) / (self.steps_)\n",
    "        self.count_ = 1\n",
    "        \n",
    "    def epsilon_update(self):\n",
    "        '''generate next epsilon value'''\n",
    "        if (self.epsilon_ >= self.stop_ and self.count_ < self.steps_):\n",
    "            self.count_ += 1\n",
    "            self.epsilon_ -= self.step_size_\n",
    "        else:\n",
    "            self.epsilon_ = self.stop_\n",
    "            self.count_ += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 8, 4)  ## Conv2d(nChannels, filters, kernel, stride)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 4, 4)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 32 * 4 * 4)  ## reshape \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.replay_size_ = None\n",
    "        self.data_ = None\n",
    "        self.target_ = None\n",
    "        \n",
    "    def get_data(self):\n",
    "        self.replay_size_ = len(minibatch)\n",
    "        # create tensor of initial observations\n",
    "        self.data_ = Variable(torch.Tensor([minibatch[i][0] for i in range(self.replay_size_)]).unsqueeze(1))\n",
    "        # create tensor of corresponding target variable values\n",
    "        target_list = []\n",
    "        for i in range(self.replay_size_):\n",
    "            observed = Variable(torch.Tensor(minibatch[i][3]))\n",
    "            if minibatch[i][4] == 'terminal':\n",
    "                target_list.append(minibatch[i][2])\n",
    "            else:\n",
    "                target_list.append(minibatch[i][2] + discount * \n",
    "                                   cnn(observed.unsqueeze(0).unsqueeze(0)).data.max(1)[1][0])\n",
    "        self.target_ = Variable(torch.Tensor(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_games = 2  ## number of games to play\n",
    "time_steps = 500  ## max number of time steps per game\n",
    "record = 0\n",
    "view = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 15:31:26,321] Making new env: Breakout-v0\n"
     ]
    }
   ],
   "source": [
    "# Atari emulator\n",
    "env = gym.make('Breakout-v0')\n",
    "# whether to record training\n",
    "if record:\n",
    "    env = wrappers.Monitor(env, \n",
    "                           directory='/Users/davidziganto/Data_Science/PyTorch/OpenAI_vids/breakout-experiment-1', \n",
    "                           video_callable=None, ## takes video when episode number is perfect cube\n",
    "                           force=True)\n",
    "\n",
    "# instantiate key classes\n",
    "cnn = CNN()\n",
    "er = ExperienceReplay(C=100)\n",
    "eg = EpsilonGenerator(start=1, stop=0.1, steps=1000)\n",
    "agent = Action()\n",
    "dataset = Dataset()\n",
    "\n",
    "# setup variables\n",
    "discount = 0.9  \n",
    "learning_rate = 0.01\n",
    "\n",
    "# CNN setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(cnn.parameters(), \n",
    "                          lr=learning_rate, \n",
    "                          alpha=0.99, \n",
    "                          eps=1e-08, \n",
    "                          weight_decay=0, \n",
    "                          momentum=0, \n",
    "                          centered=False)\n",
    "\n",
    "# play game\n",
    "for episode in range(num_games):\n",
    "    \n",
    "    ## start/reset environment + store observation\n",
    "    initial_seq = preprocess(env.reset())\n",
    "    \n",
    "    for t in range(time_steps):\n",
    "        \n",
    "        ## show game in real-time\n",
    "        if view:\n",
    "            env.render()\n",
    "        \n",
    "        # take action (0=do nothing; 1=fire ball; 2=move right; 3=move left)\n",
    "        action = agent.action()\n",
    "        agent.update_time()\n",
    "        \n",
    "        # update epsilon for epsilon-greedy implementation\n",
    "        eg.epsilon_update()\n",
    "        \n",
    "        # get feedback from emulator\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        # preprocess new observation post action    \n",
    "        final_seq = preprocess(observation)\n",
    "        \n",
    "        # stop if no more moves, else continue and update\n",
    "        if done:\n",
    "            er.add_experience((initial_seq, action, reward, final_seq, 'terminal'))\n",
    "            break\n",
    "        else:\n",
    "            er.add_experience((initial_seq, action, reward, final_seq, 'nonterminal'))\n",
    "            \n",
    "        # get mini-batch sample from experience replay (fyi - randomizes index)\n",
    "        minibatch = er.sample()\n",
    "        \n",
    "        # get data for updating policy network\n",
    "        dataset.get_data()\n",
    "        \n",
    "        # Update CNN\n",
    "        optimizer.zero_grad()  ## zero the parameter gradients\n",
    "        outputs = cnn(dataset.data_).max(1)[0]  ## feedforward pass\n",
    "        loss = criterion(outputs, dataset.target_)  ## calculate loss\n",
    "        loss.backward()  ## backpropagation\n",
    "        optimizer.step()  ## update network weights\n",
    "            \n",
    "        # set new observation as initial observation\n",
    "        initial_seq = final_seq\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do...\n",
    "\n",
    "1) normalize pixel values (preprocessing)  \n",
    "2) add loss function to show learning over time  \n",
    "3) add GPU functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats for 1000 games taking random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-v0')\n",
    "\n",
    "rewards = []\n",
    "steps = []\n",
    "\n",
    "for game in range(1000):\n",
    "    \n",
    "    myreward = 0\n",
    "    \n",
    "    # reset game\n",
    "    env.reset()\n",
    "    \n",
    "    for t in range(1000):\n",
    "        \n",
    "        # show in real-time\n",
    "        #env.render()\n",
    "        \n",
    "        # take a random action\n",
    "        if t == 0:\n",
    "            action = 1\n",
    "        else:\n",
    "            action = env.action_space.sample() \n",
    "        \n",
    "        # get feedback\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        myreward += reward\n",
    "        \n",
    "        # end game when out of balls\n",
    "        if done:\n",
    "            rewards.append(myreward)\n",
    "            steps.append(t)\n",
    "            stats = zip(steps, rewards)\n",
    "            env.close()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), '/Users/davidziganto/Data_Science/PyTorch/DL_models/DL_RL_Atari_breakout_500e_10000t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cnn = CNN()\n",
    "#cnn.load_state_dict(torch.load('/Users/davidziganto/Data_Science/PyTorch/DL_models/DL_RL_Atari_breakout'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE\n",
    "\n",
    "### Get Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "rewards = []\n",
    "nb_frames = 500\n",
    "env = gym.make('Breakout-v0')\n",
    "env.reset()\n",
    "for t in range(nb_frames):\n",
    "    env.render()\n",
    "    action = env.action_space.sample() # take a random action\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    frames.append(preprocess(observation))\n",
    "    if t%4 == 3 or done:\n",
    "        frameTensor = np.stack(frames)\n",
    "        minibatch = Variable(torch.Tensor(frameTensor))  ## convert to torch Variable data type\n",
    "        print('t:', t, '\\n', minibatch)\n",
    "        frames = []\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Preprocessed Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    plt.imshow(frame, cmap = plt.get_cmap('gray'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
